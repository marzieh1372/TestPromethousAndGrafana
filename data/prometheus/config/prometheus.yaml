#global configs, like how often it will scrape its targets.
# my global config
global:
  scrape_interval:     10s # By default, scrape targets every 15 seconds.
  evaluation_interval: 10s # By default, scrape targets every 15 seconds.
  # scrape_timeout is set to the global default (10s).

#we can declare rule files, so when we meet a certain condition, we get an alert.
# Load rules once and periodically evaluate them according to the global 'evaluation_interval'.
rule_files:
# - "first.rules"
# - "second.rules"

#which services it needs to monitor.
# A scrape configuration containing exactly one endpoint to scrape:
# Here it's Prometheus itself.
scrape_configs:
  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  - job_name: 'Test Grafana and prometheus Application (Job)'
    #Prometheus expects the data of our targets to be exposed on the /metrics endpoint,
    #unless otherwise declared in the metrics_path field.
    metrics_path: '/actuator/prometheus'
    scrape_interval: 2s
    static_configs:
      - targets: ['192.168.15.119:8080'] # ip of system
        labels:
          application: 'My Spring Boot Application'

  # The job name is added as a label `job=<job_name>` to any timeseries scraped from this config.
  # Its own health
  - job_name: 'prometheus'
    static_configs:
      - targets: [ 'localhost:9090' ]